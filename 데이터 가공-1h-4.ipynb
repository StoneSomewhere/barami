{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_1h.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2589/2589 [19:54<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etf_1h.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1186/1186 [06:43<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from WavletTransform import wavlet_transform\n",
    "\n",
    "\n",
    "base = 210  # 몇 일의 데이터를 쓸 것인가\n",
    "period = 24   # 몇 step내를 예측할 것인가\n",
    "step = 15  # 몇 step씩 이동할 것인가\n",
    "\n",
    "#pickle_list=['3bull_1h_uptodate.pickle', 'etf_1h.pickle', 'stock_1h.pckle']\n",
    "pickle_list=['stock_1h.pickle', 'etf_1h.pickle' ]\n",
    "X, Y = [],[]\n",
    "for dict_file in pickle_list:\n",
    "    print(dict_file)\n",
    "    with open(dict_file,\"rb\") as fr:\n",
    "        container = pickle.load(fr)\n",
    "\n",
    "    \n",
    "    for name in tqdm(container):\n",
    "        \n",
    "        Data = container[name]\n",
    "        Data.columns=[\"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        Data.dropna(subset=['Close'], inplace=True) \n",
    "        Data[\"Volume\"]=np.log(Data[\"Volume\"]+1)        \n",
    "        Data[\"WeightedClose\"]=Data[\"Close\"]*(Data[\"Volume\"]+1)\n",
    "        Data[\"Width\"]=Data[\"High\"]-Data[\"Low\"]\n",
    "        Data.drop([\"High\", \"Low\"], axis=1, inplace=True)\n",
    "        Data.dropna(subset=['Close'], inplace=True)\n",
    "        \n",
    "              \n",
    "            \n",
    "#        date_list = Data.iloc[base-1:].loc[:].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        date_list = Data.iloc[base-1:].loc[:\"2021073009\"].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        #date_list = Data.iloc[base-1:].index[:-period]            #예측하려는 날짜-1\n",
    "        \n",
    "        # i는 예측하려는 날-1\n",
    "        for i in date_list:\n",
    "            \n",
    "            \n",
    "            close_std=Data.loc[:i].iloc[-base:][\"Close\"].std()    #수정종가의 표준편차\n",
    "            Last_price = Data.loc[i]['Close'] + 0.0001\n",
    "            y = Data.loc[i:].iloc[1:period + 1][\"Close\"]/Last_price - 1\n",
    "            err=1\n",
    "            \n",
    "            for s in range(5, 3, -1):#4%는 변해야지\n",
    "                fluct = y[abs(y) > 0.01*s]\n",
    "                if np.shape(fluct)[0] > 0:\n",
    "                    y=fluct.iloc[0]     #후에 어떤 추가적 변동이 있었든지 가장 먼저 변동한 것만 취급한다.\n",
    "                    err=0\n",
    "                    break\n",
    "            if err==1:continue\n",
    "            \n",
    "            x = Data.loc[:i].iloc[-base:]           #예측일자 -base일\n",
    "            if x.isnull().values.any() : continue   #null값 있으면 pass   \n",
    "            x = (x-x.mean())/(x.std()+0.0001)        #정규화    \n",
    "                        \n",
    "            \n",
    "            y = (np.sign(y)+1)//2  #올랐으면 1 내렸으면 0\n",
    "            Y.append(y)\n",
    "            X.append(x)    \n",
    "#    np.save('X_%s_%d.npy' %(save_name, step), XX)\n",
    "#    np.save('Y_%s_%d.npy' %(save_name, step), YY)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408905, 210, 4)\n",
      "(192293,)\n",
      "(216612,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#균등화\\nuI = YY==1\\ndI = YY==0\\n\\nlength = min(sum(uI), sum(dI))\\n\\nXX = np.concatenate( (XX[uI][:length], XX[dI][:length]  ), axis=0)\\nYY = np.concatenate( (YY[uI][:length], YY[dI][:length]  ), axis=0)\\n\\nI = np.arange(np.shape(YY)[0])\\n\\nnp.random.shuffle(I)\\n\\nXX = XX[I]\\nYY = YY[I]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "XX = np.array(X)\n",
    "YY = np.array(Y, dtype=\"uint8\")\n",
    "\n",
    "I = np.arange(np.shape(YY)[0])\n",
    "np.random.shuffle(I)\n",
    "\n",
    "XX = XX[I]\n",
    "YY = YY[I]\n",
    "\n",
    "shape = np.shape(XX)\n",
    "print(shape)\n",
    "print(np.shape(YY[YY==0])), print(np.shape(YY[YY==1]))\n",
    "    \n",
    "#save_name=dict_file.split('.')[0]\n",
    "\n",
    "'''\n",
    "#균등화\n",
    "uI = YY==1\n",
    "dI = YY==0\n",
    "\n",
    "length = min(sum(uI), sum(dI))\n",
    "\n",
    "XX = np.concatenate( (XX[uI][:length], XX[dI][:length]  ), axis=0)\n",
    "YY = np.concatenate( (YY[uI][:length], YY[dI][:length]  ), axis=0)\n",
    "\n",
    "I = np.arange(np.shape(YY)[0])\n",
    "\n",
    "np.random.shuffle(I)\n",
    "\n",
    "XX = XX[I]\n",
    "YY = YY[I]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=2\n",
    "shape = np.shape(XX)[0]%s\n",
    "\n",
    "XX = np.split(XX[shape:], s)\n",
    "YY = np.split(YY[shape:], s)\n",
    "\n",
    "for i in range(s):\n",
    "    np.save('X_train_%d.npy' %(i+1), XX[i])\n",
    "    np.save('Y_train_%d.npy' %(i+1), YY[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etf_1h.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1186/1186 [13:14<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127176, 210, 4)\n",
      "(62375,)\n",
      "(64801,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from WavletTransform import wavlet_transform\n",
    "\n",
    "\n",
    "base = 210  # 몇 일의 데이터를 쓸 것인가\n",
    "period = 24   # 몇 step내를 예측할 것인가\n",
    "step = 8  # 몇 step씩 이동할 것인가\n",
    "\n",
    "#pickle_list=['3bull_1h_uptodate.pickle', 'etf_1h.pickle', 'stock_1h.pckle']\n",
    "pickle_list=['etf_1h.pickle', 'dummy' ]\n",
    "X, Y = [],[]\n",
    "for dict_file in pickle_list:\n",
    "    print(dict_file)\n",
    "    with open(dict_file,\"rb\") as fr:\n",
    "        container = pickle.load(fr)\n",
    "    \n",
    "    for name in tqdm(container):\n",
    "        \n",
    "        Data = container[name]\n",
    "        Data.columns=[\"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        Data.dropna(subset=['Close'], inplace=True) \n",
    "        Data[\"Volume\"]=np.log(Data[\"Volume\"]+1)        \n",
    "        Data[\"WeightedClose\"]=Data[\"Close\"]*(Data[\"Volume\"]+1)\n",
    "        Data[\"Width\"]=Data[\"High\"]-Data[\"Low\"]\n",
    "        Data.drop([\"High\", \"Low\"], axis=1, inplace=True)\n",
    "        Data.dropna(subset=['Close'], inplace=True)\n",
    "            \n",
    "#        date_list = Data.iloc[base-1:].loc[:].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        date_list = Data.iloc[base-1:].loc[:\"2021073009\"].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        #date_list = Data.iloc[base-1:].index[:-period]            #예측하려는 날짜-1\n",
    "        \n",
    "        # i는 예측하려는 날-1\n",
    "        for i in date_list:\n",
    "            \n",
    "            \n",
    "            close_std=Data.loc[:i].iloc[-base:][\"Close\"].std()    #수정종가의 표준편차\n",
    "            Last_price = Data.loc[i]['Close'] + 0.0001\n",
    "            y = Data.loc[i:].iloc[1:period + 1][\"Close\"]/Last_price - 1\n",
    "            err=1\n",
    "            \n",
    "            for s in range(4, 2, -1):#3.5%는 올라야지\n",
    "                fluct = y[abs(y) > 0.01*s+0.005]\n",
    "                if np.shape(fluct)[0] > 0:\n",
    "                    y=fluct.iloc[0]     #후에 어떤 추가적 변동이 있었든지 가장 먼저 변동한 것만 취급한다.\n",
    "                    err=0\n",
    "                    break\n",
    "            if err==1:continue\n",
    "            \n",
    "            x = Data.loc[:i].iloc[-base:]           #예측일자 -base일\n",
    "            if x.isnull().values.any() : continue   #null값 있으면 pass             \n",
    "            x = (x-x.mean())/(x.std()+0.0001)        #정규화    \n",
    "                        \n",
    "            \n",
    "            y = (np.sign(y)+1)//2  #올랐으면 1 내렸으면 0\n",
    "            Y.append(y)\n",
    "            X.append(x)    \n",
    "\n",
    "    XX = np.array(X)\n",
    "    YY = np.array(Y, dtype=\"uint8\")\n",
    "\n",
    "    I = np.arange(np.shape(YY)[0])\n",
    "    np.random.shuffle(I)\n",
    "\n",
    "    XX = XX[I]\n",
    "    YY = YY[I]\n",
    "\n",
    "    shape = np.shape(XX)\n",
    "    print(shape)\n",
    "    print(np.shape(YY[YY==0])), print(np.shape(YY[YY==1]))\n",
    "    \n",
    "    save_name=dict_file.split('.')[0]\n",
    "        \n",
    "    np.save('X_%s_%d.npy' %(save_name, step), XX)\n",
    "    np.save('Y_%s_%d.npy' %(save_name, step), YY)\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3bull_1h.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [01:09<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14945, 210, 4)\n",
      "(7021,)\n",
      "(7924,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    #균등화\\n    uI = YY==1\\n    dI = YY==0\\n\\n    length = min(sum(uI), sum(dI))\\n        \\n    XX = np.concatenate( (XX[uI][:length], XX[dI][:length]  ), axis=0)\\n    YY = np.concatenate( (YY[uI][:length], YY[dI][:length]  ), axis=0)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from WavletTransform import wavlet_transform\n",
    "\n",
    "\n",
    "base = 210  # 몇 일의 데이터를 쓸 것인가\n",
    "period = 24   # 몇 step내를 예측할 것인가\n",
    "step = 3  # 몇 step씩 이동할 것인가\n",
    "\n",
    "#pickle_list=['3bull_1h_uptodate.pickle', 'etf_1h.pickle', 'stock_1h.pckle']\n",
    "pickle_list=['3bull_1h.pickle', 'dummy' ]\n",
    "X, Y = [],[]\n",
    "for dict_file in pickle_list:\n",
    "    print(dict_file)\n",
    "    with open(dict_file,\"rb\") as fr:\n",
    "        container = pickle.load(fr)\n",
    "\n",
    "    \n",
    "    for name in tqdm(container):\n",
    "        \n",
    "        Data = container[name]\n",
    "        Data.columns=[\"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        Data.dropna(subset=['Close'], inplace=True) \n",
    "        Data[\"Volume\"]=np.log(Data[\"Volume\"]+1)        \n",
    "        Data[\"WeightedClose\"]=Data[\"Close\"]*(Data[\"Volume\"]+1)\n",
    "        Data[\"Width\"]=Data[\"High\"]-Data[\"Low\"]\n",
    "        Data.drop([\"High\", \"Low\"], axis=1, inplace=True)\n",
    "        Data.dropna(subset=['Close'], inplace=True)\n",
    "        \n",
    "              \n",
    "            \n",
    "#        date_list = Data.iloc[base-1:].loc[:].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        date_list = Data.iloc[base-1:].loc[:\"2021073009\"].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        #date_list = Data.iloc[base-1:].index[:-period]            #예측하려는 날짜-1\n",
    "        \n",
    "        # i는 예측하려는 날-1\n",
    "        for i in date_list:\n",
    "            \n",
    "            \n",
    "            close_std=Data.loc[:i].iloc[-base:][\"Close\"].std()    #수정종가의 표준편차\n",
    "            Last_price = Data.loc[i]['Close'] + 0.0001\n",
    "            y = Data.loc[i:].iloc[1:period + 1][\"Close\"]/Last_price - 1\n",
    "            err=1\n",
    "            \n",
    "            for s in range(11, 8, -1):#9%는 올라야지\n",
    "                fluct = y[abs(y) > 0.01*s]\n",
    "                if np.shape(fluct)[0] > 0:\n",
    "                    y=fluct.iloc[0]     #후에 어떤 추가적 변동이 있었든지 가장 먼저 변동한 것만 취급한다.\n",
    "                    err=0\n",
    "                    break\n",
    "            if err==1:continue\n",
    "            \n",
    "            x = Data.loc[:i].iloc[-base:]           #예측일자 -base일\n",
    "            if x.isnull().values.any() : continue   #null값 있으면 pass                   \n",
    "            x = (x-x.mean())/(x.std()+0.0001)        #정규화    \n",
    "                        \n",
    "            \n",
    "            y = (np.sign(y)+1)//2  #올랐으면 1 내렸으면 0\n",
    "            Y.append(y)\n",
    "            X.append(x)    \n",
    "\n",
    "    XX = np.array(X)\n",
    "    YY = np.array(Y, dtype=\"uint8\")\n",
    "\n",
    "    I = np.arange(np.shape(YY)[0])\n",
    "    np.random.shuffle(I)\n",
    "\n",
    "    XX = XX[I]\n",
    "    YY = YY[I]\n",
    "\n",
    "    shape = np.shape(XX)\n",
    "    print(shape)\n",
    "    print(np.shape(YY[YY==0])), print(np.shape(YY[YY==1]))\n",
    "    \n",
    "    save_name=dict_file.split('.')[0]\n",
    "        \n",
    "    np.save('X_%s_%d.npy' %(save_name, step), XX)\n",
    "    np.save('Y_%s_%d.npy' %(save_name, step), YY)\n",
    "    break\n",
    "'''\n",
    "    #균등화\n",
    "    uI = YY==1\n",
    "    dI = YY==0\n",
    "\n",
    "    length = min(sum(uI), sum(dI))\n",
    "        \n",
    "    XX = np.concatenate( (XX[uI][:length], XX[dI][:length]  ), axis=0)\n",
    "    YY = np.concatenate( (YY[uI][:length], YY[dI][:length]  ), axis=0)\n",
    "'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3bull_1h.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▊                                                                           | 3/32 [00:02<00:27,  1.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dcc1dfd84ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m           \u001b[1;31m#예측일자 -base일\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m   \u001b[1;31m#null값 있으면 pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m#정규화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11466\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11467\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11468\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  11469\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11470\u001b[0m         )\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   8539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8540\u001b[0m         dtype_is_dt = np.array(\n\u001b[1;32m-> 8541\u001b[1;33m             [\n\u001b[0m\u001b[0;32m   8542\u001b[0m                 \u001b[0mis_datetime64_any_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8543\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_column_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   8539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8540\u001b[0m         dtype_is_dt = np.array(\n\u001b[1;32m-> 8541\u001b[1;33m             [\n\u001b[0m\u001b[0;32m   8542\u001b[0m                 \u001b[0mis_datetime64_any_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8543\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_column_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_iter_column_arrays\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2865\u001b[0m         \"\"\"\n\u001b[0;32m   2866\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2867\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_column_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_column_array\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m   2857\u001b[0m         in the Block)\n\u001b[0;32m   2858\u001b[0m         \"\"\"\n\u001b[1;32m-> 2859\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2861\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_column_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miget_values\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \"\"\"\n\u001b[1;32m-> 1003\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from WavletTransform import wavlet_transform\n",
    "\n",
    "\n",
    "base = 210  # 몇 일의 데이터를 쓸 것인가\n",
    "period = 24   # 몇 step내를 예측할 것인가\n",
    "step = 1  # 몇 step씩 이동할 것인가\n",
    "\n",
    "#pickle_list=['3bull_1h_uptodate.pickle', 'etf_1h.pickle', 'stock_1h.pckle']\n",
    "pickle_list=['3bull_1h.pickle', 'dummy' ]\n",
    "X, Y = [],[]\n",
    "for dict_file in pickle_list:\n",
    "    print(dict_file)\n",
    "    with open(dict_file,\"rb\") as fr:\n",
    "        container = pickle.load(fr)\n",
    "\n",
    "    \n",
    "    for name in tqdm(container):\n",
    "        \n",
    "        Data = container[name]\n",
    "        Data.columns=[\"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        Data.dropna(subset=['Close'], inplace=True) \n",
    "        Data[\"Volume\"]=np.log(Data[\"Volume\"]+1)        \n",
    "        Data[\"WeightedClose\"]=Data[\"Close\"]*(Data[\"Volume\"]+1)\n",
    "        Data[\"Width\"]=Data[\"High\"]-Data[\"Low\"]\n",
    "        Data.drop([\"High\", \"Low\"], axis=1, inplace=True)\n",
    "        Data.dropna(subset=['Close'], inplace=True)\n",
    "        \n",
    "              \n",
    "            \n",
    "#        date_list = Data.iloc[base-1:].loc[:].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        date_list = Data.iloc[base-1:].loc[\"2021073015\":].index[:-period][::step]    # 예측하려는 날짜-1일까지 step씩\n",
    "        #date_list = Data.iloc[base-1:].index[:-period]            #예측하려는 날짜-1\n",
    "        \n",
    "        # i는 예측하려는 날-1\n",
    "        for i in date_list:\n",
    "            \n",
    "            \n",
    "            close_std=Data.loc[:i].iloc[-base:][\"Close\"].std()    #수정종가의 표준편차\n",
    "            Last_price = Data.loc[i]['Close'] + 0.0001\n",
    "            y = Data.loc[i:].iloc[1:period + 1][\"Close\"]/Last_price - 1\n",
    "            err=1\n",
    "            \n",
    "            for s in range(9, 6, -1):#7.5%는 올라야지\n",
    "                fluct = y[abs(y) > 0.01*s+0.005]\n",
    "                if np.shape(fluct)[0] > 0:\n",
    "                    y=fluct.iloc[0]     #후에 어떤 추가적 변동이 있었든지 가장 먼저 변동한 것만 취급한다.\n",
    "                    err=0\n",
    "                    break\n",
    "            if err==1:continue\n",
    "            \n",
    "            x = Data.loc[:i].iloc[-base:]           #예측일자 -base일\n",
    "            if x.isnull().values.any() : continue   #null값 있으면 pass               \n",
    "            x = (x-x.mean())/(x.std()+0.0001)        #정규화    \n",
    "                        \n",
    "            \n",
    "            y = (np.sign(y)+1)//2  #올랐으면 1 내렸으면 0\n",
    "            Y.append(y)\n",
    "            X.append(x)    \n",
    "\n",
    "    XX = np.array(X)\n",
    "    YY = np.array(Y, dtype=\"uint8\")\n",
    "\n",
    "    I = np.arange(np.shape(YY)[0])\n",
    "    np.random.shuffle(I)\n",
    "\n",
    "    XX = XX[I]\n",
    "    YY = YY[I]\n",
    "\n",
    "    shape = np.shape(XX)\n",
    "    print(shape)\n",
    "    print(np.shape(YY[YY==0])), print(np.shape(YY[YY==1]))\n",
    "    \n",
    "    save_name=dict_file.split('.')[0]\n",
    "    np.save('X_test.npy', XX)\n",
    "    np.save('Y_test.npy', YY)\n",
    "    break\n",
    "'''\n",
    "    #균등화\n",
    "    uI = YY==1\n",
    "    dI = YY==0\n",
    "\n",
    "    length = min(sum(uI), sum(dI))\n",
    "        \n",
    "    XX = np.concatenate( (XX[uI][:length], XX[dI][:length]  ), axis=0)\n",
    "    YY = np.concatenate( (YY[uI][:length], YY[dI][:length]  ), axis=0)\n",
    "'''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\"etf_1h_3\", \"train_1\", \"train_2\"]:\n",
    "\n",
    "    XX = np.load('X_%s.npy'%name)\n",
    "    YY = np.load('Y_%s.npy'%name)\n",
    "    \n",
    "    s=2\n",
    "    shape = np.shape(XX)[0]%s\n",
    "\n",
    "    XX = np.split(XX[shape:], s)\n",
    "    YY = np.split(YY[shape:], s)    \n",
    "    \n",
    "    for i in range(s):\n",
    "        np.save('X_%s_%d.npy' %(name, i+1), XX[i])\n",
    "        np.save('Y_%s_%d.npy' %(name, i+1), YY[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
